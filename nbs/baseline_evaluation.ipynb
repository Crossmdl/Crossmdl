{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluates the results on baseline model - `CLIPLSTM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/common/home/vk405/Projects/Crossmdl/nbs/csvlogs/clip_lstm/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['train_loss'].dropna().plot()\n",
    "df['val_loss'].dropna().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/vk405/miniconda3/envs/Crossmdl/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#pad your sequences\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import joblib\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "from itertools import repeat\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numpy import linalg as LA\n",
    "from argparse import Namespace\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "import logging\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import clip\n",
    "\n",
    "\n",
    "import wandb\n",
    "import logging\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "wandb_logger = lambda dir, version: WandbLogger(\n",
    "    name=\"wandb\", save_dir=dir, version=version\n",
    ")\n",
    "csvlogger = lambda dir, version: CSVLogger(dir, name=\"csvlogs\", version=version)\n",
    "tblogger = lambda dir, version: TensorBoardLogger(dir, name=\"tblogs\", version=version)\n",
    "\n",
    "def get_loggers(dir,version,lis=[\"csv\"]):\n",
    "    lgrs = []\n",
    "    if \"wandb\" in lis:\n",
    "        lgrs.append(wandb_logger(dir, version))\n",
    "    if \"csv\" in lis:\n",
    "        lgrs.append(csvlogger(dir, version))\n",
    "    if \"tb\" in lis:\n",
    "        lgrs.append(tblogger(dir, version))\n",
    "    return lgrs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_vid_ids(split='training',\\\n",
    "    annotns_file='/common/home/vk405/Projects/Crossmdl/Data/YouCookII/annotations/youcookii_annotations_trainval.json'):\n",
    "    # Returns vid_ids corresponding to the split: 'training'/'validation'\n",
    "    \n",
    "    vid_lis = []\n",
    "    with open(annotns_file) as json_file:\n",
    "        annotns = json.load(json_file)['database']\n",
    "        for key in annotns:\n",
    "            if annotns[key]['subset'] == split:\n",
    "                vid_lis.append(key)\n",
    "    return vid_lis\n",
    "\n",
    "\n",
    "def get_split_files(split='training',\\\n",
    "    annotns_file='/common/home/vk405/Projects/Crossmdl/Data/YouCookII/annotations/youcookii_annotations_trainval.json',\\\n",
    "        data_dir = '/common/users/vk405/Youcook/'):\n",
    "    total_ids = get_vid_ids(split,annotns_file)\n",
    "    downloaded_ids = set([dir for dir in os.listdir(data_dir) if 'joblib' not in dir])\n",
    "    vid_locs = []\n",
    "    sents = {}\n",
    "    segs = {}\n",
    "    incomplete = []\n",
    "    for id in total_ids:\n",
    "        if id in downloaded_ids:\n",
    "            vid_loc = data_dir+id + '/'\n",
    "            if len(os.listdir(vid_loc))>=495:\n",
    "                vid_locs.append(vid_loc)\n",
    "                seg = joblib.load(data_dir+f'{id}global_segs.joblib')\n",
    "                sent = joblib.load(data_dir+f'{id}global_sents.joblib')\n",
    "                try:\n",
    "                    sents[id] = sent[id]\n",
    "                    segs[id] = seg[id]\n",
    "                except:\n",
    "                    print(f\"{id} is no corresponding global sent/seg\")\n",
    "            else:\n",
    "                #print(f\"{id} has only imgs {len(os.listdir(vid_loc))}\")\n",
    "                incomplete.append(id)\n",
    "    return vid_locs,segs,sents,incomplete \n",
    "\n",
    "import pathlib\n",
    "\n",
    "FEAT_DIR = pathlib.Path('/common/users/vk405/CLIP_FEAT')\n",
    "RAWFRAME_DIR = pathlib.Path('/common/users/vk405/Youcook/')\n",
    "\n",
    "class Dset(Dataset):\n",
    "    def __init__(self,data_dir,feat_dir,split='training'):\n",
    "        self.data_dir = data_dir\n",
    "        self.feat_dir = feat_dir\n",
    "        self.split = split\n",
    "        self.vid_ids,self.sents = self.get_ids()\n",
    "        self.labels = self.getlabels()\n",
    "        self.sanitycheck()\n",
    "        self.data = self.getdata()\n",
    "        \n",
    "\n",
    "\n",
    "    def sanitycheck(self):\n",
    "        mis = []\n",
    "        #import pdb;pdb.set_trace()\n",
    "        for key in self.labels.keys():\n",
    "            txt_loc = self.feat_dir/self.split/f'txt_{key}.joblib'\n",
    "            txt = joblib.load(txt_loc)\n",
    "            if len(self.labels[key]) == len(self.sents[key]) == len(txt):\n",
    "                pass\n",
    "            else:\n",
    "                print(key)\n",
    "                mis.append(key)\n",
    "        print(f\"segs are not matching:{mis}\")\n",
    "        for key in mis:\n",
    "            self.vid_ids.remove(key)\n",
    "        self.sents = None\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.load(self.data[idx])\n",
    "\n",
    "    def getdata(self):\n",
    "        data = []\n",
    "        for id in self.vid_ids:\n",
    "            segs = self.labels[id]\n",
    "            #import pdb;pdb.set_trace()\n",
    "            for i in range(len(segs)):\n",
    "                data.append((id,i))\n",
    "        return data\n",
    "\n",
    "    def load(self,data):\n",
    "        vid_id,ind = data\n",
    "        vid_frames_loc = self.feat_dir/self.split/f'vid_{vid_id}.joblib'\n",
    "        txt_loc = self.feat_dir/self.split/f'txt_{vid_id}.joblib'\n",
    "        st,end = self.labels[vid_id][ind]\n",
    "        vid = joblib.load(vid_frames_loc)\n",
    "        try:\n",
    "            txt = joblib.load(txt_loc)[ind]\n",
    "        except:\n",
    "            import pdb;pdb.set_trace()\n",
    "        #normalize data\n",
    "        #import pdb;pdb.set_trace()\n",
    "        vid = vid/(LA.norm(vid,axis=-1)).reshape(500,1)\n",
    "        txt = (txt/LA.norm(txt))\n",
    "        #out = np.squeeze(vid@txt.reshape(512,1))\n",
    "        #regression outputs\n",
    "        return vid,txt,st/499,end/499\n",
    "         \n",
    "\n",
    "    def getlabels(self):\n",
    "        label_dict = {}\n",
    "        for vidid in self.vid_ids:\n",
    "            vidloc = self.data_dir/vidid\n",
    "            segs = self.extract_seg(vidloc)\n",
    "            label_dict[vidid] = segs\n",
    "        return label_dict\n",
    "    \n",
    "    def extract_seg(self,vid_loc):\n",
    "        imgs = sorted(os.listdir(vid_loc),key=lambda x: int(x.split('_')[0]))\n",
    "        segs = defaultdict(list)\n",
    "        for img in imgs:\n",
    "            ind,rem = int(img.split('_')[0]),img.split('_')[-1]\n",
    "            \n",
    "            if 'n.' not in rem:\n",
    "                #print(ind,rem)\n",
    "                seg_id = int(rem.split('.')[0])\n",
    "                segs[seg_id].append(ind)\n",
    "                #print(seg_id,ind)\n",
    "        final_segs = []\n",
    "        #import pdb;pdb.set_trace()\n",
    "        segids = sorted(segs.keys())\n",
    "        for segid in segids:\n",
    "            final_segs.append((min(segs[segid]),max(segs[segid])))\n",
    "        return final_segs\n",
    "        \n",
    "    def get_ids(self):\n",
    "        annotns_file='/common/home/vk405/Projects/Crossmdl/Data/YouCookII/annotations/youcookii_annotations_trainval.json'\n",
    "        data_dir = '/common/users/vk405/Youcook/'\n",
    "        vid_locs,_,sents,_ = get_split_files(self.split,annotns_file,data_dir)\n",
    "        ids = [ele.split('/')[-2] for ele in vid_locs]\n",
    "        files = set(os.listdir(self.feat_dir/self.split))\n",
    "        finids = []\n",
    "        missing = []\n",
    "        for id in ids:\n",
    "            if f'vid_{id}.joblib' in files:\n",
    "                finids.append(id)\n",
    "            else:missing.append(id)\n",
    "        print(f\"missing:{missing}\")\n",
    "        return finids,sents\n",
    "class ClipLstm(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.vid_encoder,self.text_encoder,self.finlin = self.get_nets(**self.hparams.network_params)\n",
    "        \n",
    "    def get_nets(self,bidirectional = True,vid_lyrs = 2,vid_hidim=64,vid_fsz=64\\\n",
    "        ,txt_lyrs=2,txt_fsz=64,act='Relu'):\n",
    "        vid_enc = []\n",
    "        last_dim = 512\n",
    "        \n",
    "        self.lstm = nn.LSTM(last_dim,vid_hidim,\\\n",
    "        vid_lyrs,bidirectional=bidirectional,batch_first=True)\n",
    "        vid_enc.append(self.lstm)\n",
    "        if act == 'Relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        vid_enc.append(self.activation)\n",
    "        self.vidfinlyr = nn.Linear(vid_hidim,vid_fsz)\n",
    "        vid_enc.append(self.vidfinlyr)\n",
    "        self.txtlyr = nn.Linear(512,txt_fsz)\n",
    "        txt_enc = nn.Sequential(self.txtlyr,self.activation)\n",
    "        \n",
    "        return vid_enc,txt_enc,nn.Linear(txt_fsz,2)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,vid,txt):\n",
    "        # modeling end = st+diff(positive/sigmoid)\n",
    "        #fixing for now\n",
    "        #torch.squeeze(self.start(self.shared(input)))\n",
    "        lstm,act,lin = self.vid_encoder\n",
    "        hiddens, (final_h, final_c) = lstm(vid.float())\n",
    "        vid_out = lin(act(torch.mean(final_h,dim=0)))\n",
    "        txt_out = self.text_encoder(txt.float())\n",
    "        preds = torch.sigmoid(self.finlin(vid_out+txt_out))\n",
    "        st_p = preds[:,0]\n",
    "        diff = preds[:,-1]\n",
    "        fin_pred = torch.stack([st_p,st_p+diff],-1)\n",
    "        return fin_pred\n",
    "\n",
    "    def giou(self,p,g):\n",
    "        x1_p,_ = torch.min(p,1)\n",
    "        x2_p,_ = torch.max(p,1)\n",
    "\n",
    "        x1_g,_ = torch.min(g,1)\n",
    "        x2_g,_ = torch.max(g,1)\n",
    "\n",
    "        x_1_i,_ =  torch.max(torch.stack([x1_g,x1_p],1),1)\n",
    "        x_2_i,_ = torch.min(torch.stack([x2_g,x2_p],1),1)\n",
    "\n",
    "        x_1_c,_ = torch.min(torch.stack([x1_p,x1_g],1),1)\n",
    "        x_2_c,_ = torch.max(torch.stack([x2_p,x2_g],1),1)\n",
    "\n",
    "        I = x_2_i - x_1_i\n",
    "        U = (x2_p-x1_p) + (x2_g-x1_g) - I\n",
    "        AC = x_2_c-x_1_c\n",
    "\n",
    "        return (I/U) - ((AC-U)/AC),(I/U)\n",
    "\n",
    "\n",
    "        \n",
    "    def training_step(self,batch,batch_idx):\n",
    "\n",
    "        vid,txt,st,end = batch\n",
    "        loss_fn = nn.MSELoss()\n",
    "        # forward\n",
    "        lstm,act,lin = self.vid_encoder\n",
    "        hiddens, (final_h, final_c) = lstm(vid.float())\n",
    "        vid_out = lin(act(torch.mean(final_h,dim=0)))\n",
    "        txt_out = self.text_encoder(txt.float())\n",
    "        preds = torch.sigmoid(self.finlin(vid_out+txt_out))\n",
    "        st_p = preds[:,0]\n",
    "        diff = preds[:,-1]\n",
    "        fin_preds = torch.stack([st_p,st_p+diff],-1)\n",
    "\n",
    "\n",
    "        grounds = torch.stack([torch.squeeze(st),torch.squeeze(end)],1)\n",
    "        giou,iou = self.giou(fin_preds,grounds)\n",
    "        loss = torch.mean(-1*giou)\n",
    "        #preds = self(vid,txt)\n",
    "        #st_loss = loss_fn(preds[:,0].float(),torch.squeeze(st).float())\n",
    "        #end_loss = loss_fn(preds[:,1].float(),torch.squeeze(end).float())\n",
    "        #loss_end = nn.CrossEntropyLoss()\n",
    "        #import pdb;pdb.set_trace()\n",
    "        #st_l = loss_st(torch.squeeze(self.start(self.shared(input))).float(),st.float())\n",
    "        #end_l = loss_st(torch.squeeze(self.end(self.shared(input))).float(),end.float())\n",
    "        #loss = st_loss + end_loss\n",
    "        self.log(\"train_loss\",loss,on_step=True)\n",
    "        self.log(\"train_iou\",torch.mean(iou),on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "\n",
    "        vid,txt,st,end = batch\n",
    "        loss_fn = nn.MSELoss()\n",
    "        # forward\n",
    "        lstm,act,lin = self.vid_encoder\n",
    "        hiddens, (final_h, final_c) = lstm(vid.float())\n",
    "        vid_out = lin(act(torch.mean(final_h,dim=0)))\n",
    "        txt_out = self.text_encoder(txt.float())\n",
    "        preds = torch.sigmoid(self.finlin(vid_out+txt_out))\n",
    "        st_p = preds[:,0]\n",
    "        diff = preds[:,-1]\n",
    "        fin_preds = torch.stack([st_p,st_p+diff],-1)\n",
    "\n",
    "        grounds = torch.stack([torch.squeeze(st),torch.squeeze(end)],1)\n",
    "        giou,iou = self.giou(fin_preds,grounds)\n",
    "        loss = torch.mean(-1*giou)\n",
    "        #loss = torch.mean(-1*self.giou(preds,grounds))\n",
    "        #preds = self(vid,txt)\n",
    "        #st_loss = loss_fn(preds[:,0].float(),torch.squeeze(st).float())\n",
    "        #end_loss = loss_fn(preds[:,1].float(),torch.squeeze(end).float())\n",
    "        #loss_end = nn.CrossEntropyLoss()\n",
    "        #import pdb;pdb.set_trace()\n",
    "        #st_l = loss_st(torch.squeeze(self.start(self.shared(input))).float(),st.float())\n",
    "        #end_l = loss_st(torch.squeeze(self.end(self.shared(input))).float(),end.float())\n",
    "        #loss = st_loss + end_loss\n",
    "        self.log(\"val_loss\",loss,on_step=False,on_epoch=True)\n",
    "        self.log(\"val_iou\",torch.mean(iou),on_step=False,on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "from argparse import Namespace\n",
    "FEAT_DIR = pathlib.Path('/common/users/vk405/CLIP_FEAT')\n",
    "RAWFRAME_DIR = pathlib.Path('/common/users/vk405/Youcook/')\n",
    "#early_stop\n",
    "cfg = Namespace(\n",
    "    version = 'clip_lstm',\n",
    "    retrain = 'true',\n",
    "    id = 0,\n",
    "    FEAT_DIR = FEAT_DIR,\n",
    "    RAWFRAME_DIR = RAWFRAME_DIR,\n",
    "    artifacts_loc = \"/common/home/vk405/Projects/Crossmdl/nbs/\",\n",
    "    data_dir = \"/common/home/vk405/Projects/Crossmdl/Data/YouCookII/\",\n",
    "    trn_split = 0.8,\n",
    "    mode = 'train',\n",
    "    split = 'training',\n",
    "    loggers = [\"csv\"],\n",
    "    seed = 0,\n",
    "    network_params = {'bidirectional':True,'vid_lyrs':2,\\\n",
    "        'vid_hidim':64,'vid_fsz':64\\\n",
    "        ,'txt_lyrs':2,'txt_fsz':64,'act':'Relu'},\n",
    "    cbs = [\"checkpoint\"],\n",
    "    trainer = {'log_every_n_steps': 1,\n",
    "    'max_epochs': 150},\n",
    "    checkpoint = {\"every_n_epochs\": 1,\n",
    "    \"monitor\": \"val_loss\"},\n",
    "    early_stop = {\"monitor\":\"val_loss\",\"mode\":\"min\",\"patience\":5},\n",
    "    lr = 1e-4\n",
    "\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing:['ukfCQQpZ0k4', 'NK2xHVWojgY', 'mixdagZ-fwI']\n",
      "cwsDQ7M5OTI\n",
      "uf65nfh6X2U\n",
      "segs are not matching:['cwsDQ7M5OTI', 'uf65nfh6X2U']\n"
     ]
    }
   ],
   "source": [
    "d = Dset(cfg.RAWFRAME_DIR,cfg.FEAT_DIR)\n",
    "tl = DataLoader(d,batch_size=64,shuffle=False,num_workers = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=73-train_loss=-0.13.ckpt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "net = ClipLstm(cfg)\n",
    "PATH = Path(cfg.artifacts_loc)/'ckpts'/cfg.version\n",
    "ckpt = os.listdir(PATH)[0]\n",
    "print(f'{ckpt}')\n",
    "new_model = net.load_from_checkpoint(checkpoint_path=str(PATH/ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClipLstm(\n",
       "  (lstm): LSTM(512, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (activation): ReLU()\n",
       "  (vidfinlyr): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (txtlyr): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (text_encoder): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (finlin): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def intersec_union(dl,model):\n",
    "    orig = []\n",
    "    pred = []\n",
    "    model.eval()\n",
    "    for batch in tqdm(dl):\n",
    "        vid,txt,st,end = batch\n",
    "        preds = model(vid,txt)\n",
    "        orig.append(torch.stack([st,end],axis=-1))\n",
    "        pred.append(preds)\n",
    "    return torch.concat(orig,axis=0),torch.concat(pred,axis=0)\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [01:31<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "o,p = intersec_union(tl,new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giou(p,g):\n",
    "    x1_p,_ = torch.min(p,1)\n",
    "    x2_p,_ = torch.max(p,1)\n",
    "\n",
    "    x1_g,_ = torch.min(g,1)\n",
    "    x2_g,_ = torch.max(g,1)\n",
    "\n",
    "    x_1_i,_ =  torch.max(torch.stack([x1_g,x1_p],1),1)\n",
    "    x_2_i,_ = torch.min(torch.stack([x2_g,x2_p],1),1)\n",
    "\n",
    "    x_1_c,_ = torch.min(torch.stack([x1_p,x1_g],1),1)\n",
    "    x_2_c,_ = torch.max(torch.stack([x2_p,x2_g],1),1)\n",
    "\n",
    "    I = x_2_i - x_1_i\n",
    "    U = (x2_p-x1_p) + (x2_g-x1_g) - I\n",
    "    #AC = x_2_c-x_1_c\n",
    "\n",
    "    return (I/U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = giou(p,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(14.2388)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(out).detach().numpy()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking baseline-1 \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/common/home/vk405/Projects/Crossmdl/nbs/csvlogs/clip/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corresponding dset\n",
    "\n",
    "import pathlib\n",
    "\n",
    "FEAT_DIR = pathlib.Path('/common/users/vk405/CLIP_FEAT')\n",
    "RAWFRAME_DIR = pathlib.Path('/common/users/vk405/Youcook/')\n",
    "\n",
    "class Dset(Dataset):\n",
    "    def __init__(self,data_dir,feat_dir,split):\n",
    "        self.data_dir = data_dir\n",
    "        self.feat_dir = feat_dir\n",
    "        self.split = split\n",
    "        self.vid_ids,self.sents = self.get_ids()\n",
    "        self.labels = self.getlabels()\n",
    "        self.sanitycheck()\n",
    "        self.data = self.getdata()\n",
    "        \n",
    "\n",
    "\n",
    "    def sanitycheck(self):\n",
    "        mis = []\n",
    "        #import pdb;pdb.set_trace()\n",
    "        for key in self.labels.keys():\n",
    "            txt_loc = self.feat_dir/self.split/f'txt_{key}.joblib'\n",
    "            txt = joblib.load(txt_loc)\n",
    "            if len(self.labels[key]) == len(self.sents[key]) == len(txt):\n",
    "                pass\n",
    "            else:\n",
    "                print(key)\n",
    "                mis.append(key)\n",
    "        print(f\"segs are not matching:{mis}\")\n",
    "        for key in mis:\n",
    "            self.vid_ids.remove(key)\n",
    "        self.sents = None\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.load(self.data[idx])\n",
    "\n",
    "    def getdata(self):\n",
    "        data = []\n",
    "        for id in self.vid_ids:\n",
    "            segs = self.labels[id]\n",
    "            #import pdb;pdb.set_trace()\n",
    "            for i in range(len(segs)):\n",
    "                data.append((id,i))\n",
    "        return data\n",
    "\n",
    "    def load(self,data):\n",
    "        vid_id,ind = data\n",
    "        vid_frames_loc = self.feat_dir/self.split/f'vid_{vid_id}.joblib'\n",
    "        txt_loc = self.feat_dir/self.split/f'txt_{vid_id}.joblib'\n",
    "        st,end = self.labels[vid_id][ind]\n",
    "        vid = joblib.load(vid_frames_loc)\n",
    "        try:\n",
    "            txt = joblib.load(txt_loc)[ind]\n",
    "        except:\n",
    "            import pdb;pdb.set_trace()\n",
    "        #normalize data\n",
    "        #import pdb;pdb.set_trace()\n",
    "        vid = vid/(LA.norm(vid,axis=-1)).reshape(500,1)\n",
    "        txt = (txt/LA.norm(txt))\n",
    "        out = np.squeeze(vid@txt.reshape(512,1))\n",
    "        #regression outputs\n",
    "        return out,st/499,end/499\n",
    "         \n",
    "\n",
    "    def getlabels(self):\n",
    "        label_dict = {}\n",
    "        for vidid in self.vid_ids:\n",
    "            vidloc = self.data_dir/vidid\n",
    "            segs = self.extract_seg(vidloc)\n",
    "            label_dict[vidid] = segs\n",
    "        return label_dict\n",
    "    \n",
    "    def extract_seg(self,vid_loc):\n",
    "        imgs = sorted(os.listdir(vid_loc),key=lambda x: int(x.split('_')[0]))\n",
    "        segs = defaultdict(list)\n",
    "        for img in imgs:\n",
    "            ind,rem = int(img.split('_')[0]),img.split('_')[-1]\n",
    "            \n",
    "            if 'n.' not in rem:\n",
    "                #print(ind,rem)\n",
    "                seg_id = int(rem.split('.')[0])\n",
    "                segs[seg_id].append(ind)\n",
    "                #print(seg_id,ind)\n",
    "        final_segs = []\n",
    "        #import pdb;pdb.set_trace()\n",
    "        segids = sorted(segs.keys())\n",
    "        for segid in segids:\n",
    "            final_segs.append((min(segs[segid]),max(segs[segid])))\n",
    "        return final_segs\n",
    "        \n",
    "    def get_ids(self):\n",
    "        annotns_file='/common/home/vk405/Projects/Crossmdl/Data/YouCookII/annotations/youcookii_annotations_trainval.json'\n",
    "        data_dir = '/common/users/vk405/Youcook/'\n",
    "        vid_locs,_,sents,_ = get_split_files(self.split,annotns_file,data_dir)\n",
    "        ids = [ele.split('/')[-2] for ele in vid_locs]\n",
    "        files = set(os.listdir(self.feat_dir/self.split))\n",
    "        finids = []\n",
    "        missing = []\n",
    "        for id in ids:\n",
    "            if f'vid_{id}.joblib' in files:\n",
    "                finids.append(id)\n",
    "            else:missing.append(id)\n",
    "        print(f\"missing:{missing}\")\n",
    "        return finids,sents\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing:[]\n",
      "95WMX64RIBc\n",
      "segs are not matching:['95WMX64RIBc']\n"
     ]
    }
   ],
   "source": [
    "d = Dset(RAWFRAME_DIR,FEAT_DIR,'validation')\n",
    "tl = DataLoader(d,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model \n",
    "\n",
    "class BaselineModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.shared = nn.Sequential(nn.Linear(500,250),nn.ReLU(),nn.Linear(250,125),nn.ReLU(),nn.Linear(125,2),nn.Sigmoid())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #fixing for now\n",
    "        #torch.squeeze(self.start(self.shared(input)))\n",
    "        return self.shared(x)\n",
    "\n",
    "    def giou(self,p,g):\n",
    "        x1_p,_ = torch.min(p,1)\n",
    "        x2_p,_ = torch.max(p,1)\n",
    "\n",
    "        x1_g,_ = torch.min(g,1)\n",
    "        x2_g,_ = torch.max(g,1)\n",
    "\n",
    "        x_1_i,_ =  torch.max(torch.stack([x1_g,x1_p],1),1)\n",
    "        x_2_i,_ = torch.min(torch.stack([x2_g,x2_p],1),1)\n",
    "\n",
    "        x_1_c,_ = torch.min(torch.stack([x1_p,x1_g],1),1)\n",
    "        x_2_c,_ = torch.max(torch.stack([x2_p,x2_g],1),1)\n",
    "\n",
    "        I = x_2_i - x_1_i\n",
    "        U = (x2_p-x1_p) + (x2_g-x1_g) - I\n",
    "        AC = x_2_c-x_1_c\n",
    "\n",
    "        return (I/U) - ((AC-U)/AC),(I/U)\n",
    "            \n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "\n",
    "        input,st,end = batch\n",
    "        preds = self(input)\n",
    "        st_p = preds[:,0]\n",
    "        diff = preds[:,-1]\n",
    "        fin_pred = torch.stack([st_p,st_p+diff],-1)\n",
    "        grounds = torch.stack([torch.squeeze(st),torch.squeeze(end)],1)\n",
    "        giou,iou = self.giou(fin_pred,grounds)\n",
    "        loss = torch.mean(-1*giou)\n",
    "\n",
    "        self.log(\"train_loss\",loss,on_step=True)\n",
    "        self.log(\"train_iou\",torch.mean(iou),on_step=True)\n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        input,st,end = batch\n",
    "        preds = self(input)\n",
    "        st_p = preds[:,0]\n",
    "        diff = preds[:,-1]\n",
    "        fin_pred = torch.stack([st_p,st_p+diff],-1)\n",
    "        grounds = torch.stack([torch.squeeze(st),torch.squeeze(end)],1)\n",
    "        giou,iou = self.giou(fin_pred,grounds)\n",
    "        loss = torch.mean(-1*giou)\n",
    "\n",
    "        self.log(\"val_loss\",loss,on_step=True)\n",
    "        self.log(\"val_iou\",torch.mean(iou),on_step=True)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=65-train_loss=-0.09.ckpt\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "FEAT_DIR = pathlib.Path('/common/users/vk405/CLIP_FEAT')\n",
    "RAWFRAME_DIR = pathlib.Path('/common/users/vk405/Youcook/')\n",
    "\n",
    "cfg = Namespace(\n",
    "    version = 'clip',\n",
    "    id = 0,\n",
    "    FEAT_DIR = FEAT_DIR,\n",
    "    RAWFRAME_DIR = RAWFRAME_DIR,\n",
    "    artifacts_loc = \"/common/home/vk405/Projects/Crossmdl/nbs/\",\n",
    "    data_dir = \"/common/home/vk405/Projects/Crossmdl/Data/YouCookII/\",\n",
    "    trn_split = 0.8,\n",
    "    mode = 'train',\n",
    "    split = 'training',\n",
    "    loggers = [\"csv\"],\n",
    "    seed = 0,\n",
    "    cbs = [\"checkpoint\",\"early_stop\"],\n",
    "    trainer = {'log_every_n_steps': 1,\n",
    "    'max_epochs': 100},\n",
    "    checkpoint = {\"every_n_epochs\": 1,\n",
    "    \"monitor\": \"val_loss\"},\n",
    "    early_stop = {\"monitor\":\"val_loss\",\"mode\":\"min\",\"patience\":5},\n",
    "    lr = 1e-4\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "net = BaselineModel(cfg)\n",
    "PATH = Path(cfg.artifacts_loc)/'ckpts'/cfg.version\n",
    "ckpt = os.listdir(PATH)[1]\n",
    "print(f'{ckpt}')\n",
    "new_model = net.load_from_checkpoint(checkpoint_path=str(PATH/ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def intersec_union(dl,model):\n",
    "    orig = []\n",
    "    pred = []\n",
    "    model.eval()\n",
    "    for batch in tqdm(dl):\n",
    "        sim,st,end = batch\n",
    "        preds = model(sim)\n",
    "        st_p = preds[:,0]\n",
    "        diff = preds[:,-1]\n",
    "        fin_pred = torch.stack([st_p,st_p+diff],-1)\n",
    "        orig.append(torch.stack([st,end],axis=-1))\n",
    "        pred.append(fin_pred)\n",
    "    return torch.concat(orig,axis=0),torch.concat(pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:15<00:00,  2.71s/it]\n"
     ]
    }
   ],
   "source": [
    "o,p = intersec_union(tl,new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = giou(p,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.2427, dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(out)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba0eaf5009993b745d4aa7d6cba132d7a7c20d53b6841ddae3db28e24457bb23"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Crossmdl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
