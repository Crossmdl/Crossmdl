{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS536.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0vTm5CvZ7l9",
        "outputId": "e1fba179-65ac-4df6-a87e-59d91470394a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = ['Copy of embeddings_test1.pkl','Copy of embeddings_train1.pkl','Copy of embeddings_val1.pkl']\n",
        "\n",
        "file_loc = {'train': f'/content/drive/MyDrive/{files[1]}','test':f'/content/drive/MyDrive/{files[0]}',\n",
        "            'valid':f'/content/drive/MyDrive/{files[-1]}'}"
      ],
      "metadata": {
        "id": "pn-bbWamaGW-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILITIES"
      ],
      "metadata": {
        "id": "_jQVWYMymult"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class cca_loss():\n",
        "    def __init__(self, outdim_size, use_all_singular_values, device):\n",
        "        self.outdim_size = outdim_size\n",
        "        self.use_all_singular_values = use_all_singular_values\n",
        "        self.device = device\n",
        "        # print(device)\n",
        "\n",
        "    def loss(self, H1, H2):\n",
        "        \"\"\"\n",
        "        It is the loss function of CCA as introduced in the original paper. There can be other formulations.\n",
        "        \"\"\"\n",
        "\n",
        "        r1 = 1e-3\n",
        "        r2 = 1e-3\n",
        "        eps = 1e-9\n",
        "\n",
        "        H1, H2 = H1.t(), H2.t()\n",
        "        # assert torch.isnan(H1).sum().item() == 0\n",
        "        # assert torch.isnan(H2).sum().item() == 0\n",
        "\n",
        "        o1 = o2 = H1.size(0)\n",
        "\n",
        "        m = H1.size(1)\n",
        "#         print(H1.size())\n",
        "\n",
        "        H1bar = H1 - H1.mean(dim=1).unsqueeze(dim=1)\n",
        "        H2bar = H2 - H2.mean(dim=1).unsqueeze(dim=1)\n",
        "        # assert torch.isnan(H1bar).sum().item() == 0\n",
        "        # assert torch.isnan(H2bar).sum().item() == 0\n",
        "\n",
        "        SigmaHat12 = (1.0 / (m - 1)) * torch.matmul(H1bar, H2bar.t())\n",
        "        SigmaHat11 = (1.0 / (m - 1)) * torch.matmul(H1bar,\n",
        "                                                    H1bar.t()) + r1 * torch.eye(o1, device=self.device)\n",
        "        SigmaHat22 = (1.0 / (m - 1)) * torch.matmul(H2bar,\n",
        "                                                    H2bar.t()) + r2 * torch.eye(o2, device=self.device)\n",
        "        # assert torch.isnan(SigmaHat11).sum().item() == 0\n",
        "        # assert torch.isnan(SigmaHat12).sum().item() == 0\n",
        "        # assert torch.isnan(SigmaHat22).sum().item() == 0\n",
        "\n",
        "        # Calculating the root inverse of covariance matrices by using eigen decomposition\n",
        "        [D1, V1] = torch.symeig(SigmaHat11, eigenvectors=True)\n",
        "        [D2, V2] = torch.symeig(SigmaHat22, eigenvectors=True)\n",
        "        # assert torch.isnan(D1).sum().item() == 0\n",
        "        # assert torch.isnan(D2).sum().item() == 0\n",
        "        # assert torch.isnan(V1).sum().item() == 0\n",
        "        # assert torch.isnan(V2).sum().item() == 0\n",
        "\n",
        "        # Added to increase stability\n",
        "        posInd1 = torch.gt(D1, eps).nonzero()[:, 0]\n",
        "        D1 = D1[posInd1]\n",
        "        V1 = V1[:, posInd1]\n",
        "        posInd2 = torch.gt(D2, eps).nonzero()[:, 0]\n",
        "        D2 = D2[posInd2]\n",
        "        V2 = V2[:, posInd2]\n",
        "        # print(posInd1.size())\n",
        "        # print(posInd2.size())\n",
        "\n",
        "        SigmaHat11RootInv = torch.matmul(\n",
        "            torch.matmul(V1, torch.diag(D1 ** -0.5)), V1.t())\n",
        "        SigmaHat22RootInv = torch.matmul(\n",
        "            torch.matmul(V2, torch.diag(D2 ** -0.5)), V2.t())\n",
        "\n",
        "        Tval = torch.matmul(torch.matmul(SigmaHat11RootInv,\n",
        "                                         SigmaHat12), SigmaHat22RootInv)\n",
        "#         print(Tval.size())\n",
        "\n",
        "        if self.use_all_singular_values:\n",
        "            # all singular values are used to calculate the correlation\n",
        "            tmp = torch.matmul(Tval.t(), Tval)\n",
        "            corr = torch.trace(torch.sqrt(tmp))\n",
        "            # assert torch.isnan(corr).item() == 0\n",
        "        else:\n",
        "            # just the top self.outdim_size singular values are used\n",
        "            trace_TT = torch.matmul(Tval.t(), Tval)\n",
        "            trace_TT = torch.add(trace_TT, (torch.eye(trace_TT.shape[0])*r1).to(self.device)) # regularization for more stability\n",
        "            U, V = torch.symeig(trace_TT, eigenvectors=True)\n",
        "            U = torch.where(U>eps, U, (torch.ones(U.shape).double()*eps).to(self.device))\n",
        "            U = U.topk(self.outdim_size)[0]\n",
        "            corr = torch.sum(torch.sqrt(U))\n",
        "        return -corr"
      ],
      "metadata": {
        "id": "h06YZeFemw6g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "\n",
        "class linear_cca():\n",
        "    def __init__(self):\n",
        "        self.w = [None, None]\n",
        "        self.m = [None, None]\n",
        "\n",
        "    def fit(self, H1, H2, outdim_size):\n",
        "        \"\"\"\n",
        "        An implementation of linear CCA\n",
        "        # Arguments:\n",
        "            H1 and H2: the matrices containing the data for view 1 and view 2. Each row is a sample.\n",
        "            outdim_size: specifies the number of new features\n",
        "        # Returns\n",
        "            A and B: the linear transformation matrices\n",
        "            mean1 and mean2: the means of data for both views\n",
        "        \"\"\"\n",
        "        r1 = 1e-4\n",
        "        r2 = 1e-4\n",
        "\n",
        "        m = H1.shape[0]\n",
        "        o1 = H1.shape[1]\n",
        "        o2 = H2.shape[1]\n",
        "\n",
        "        self.m[0] = numpy.mean(H1, axis=0)\n",
        "        self.m[1] = numpy.mean(H2, axis=0)\n",
        "        H1bar = H1 - numpy.tile(self.m[0], (m, 1))\n",
        "        H2bar = H2 - numpy.tile(self.m[1], (m, 1))\n",
        "\n",
        "        SigmaHat12 = (1.0 / (m - 1)) * numpy.dot(H1bar.T, H2bar)\n",
        "        SigmaHat11 = (1.0 / (m - 1)) * numpy.dot(H1bar.T,\n",
        "                                                 H1bar) + r1 * numpy.identity(o1)\n",
        "        SigmaHat22 = (1.0 / (m - 1)) * numpy.dot(H2bar.T,\n",
        "                                                 H2bar) + r2 * numpy.identity(o2)\n",
        "\n",
        "        [D1, V1] = numpy.linalg.eigh(SigmaHat11)\n",
        "        [D2, V2] = numpy.linalg.eigh(SigmaHat22)\n",
        "        SigmaHat11RootInv = numpy.dot(\n",
        "            numpy.dot(V1, numpy.diag(D1 ** -0.5)), V1.T)\n",
        "        SigmaHat22RootInv = numpy.dot(\n",
        "            numpy.dot(V2, numpy.diag(D2 ** -0.5)), V2.T)\n",
        "\n",
        "        Tval = numpy.dot(numpy.dot(SigmaHat11RootInv,\n",
        "                                   SigmaHat12), SigmaHat22RootInv)\n",
        "\n",
        "        [U, D, V] = numpy.linalg.svd(Tval)\n",
        "        V = V.T\n",
        "        self.w[0] = numpy.dot(SigmaHat11RootInv, U[:, 0:outdim_size])\n",
        "        self.w[1] = numpy.dot(SigmaHat22RootInv, V[:, 0:outdim_size])\n",
        "        D = D[0:outdim_size]\n",
        "\n",
        "    def _get_result(self, x, idx):\n",
        "        result = x - self.m[idx].reshape([1, -1]).repeat(len(x), axis=0)\n",
        "        result = numpy.dot(result, self.w[idx])\n",
        "        return result\n",
        "\n",
        "    def test(self, H1, H2):\n",
        "        return self._get_result(H1, 0), self._get_result(H2, 1)"
      ],
      "metadata": {
        "id": "lUZfJPZxmyVi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "#from objectives import cca_loss\n",
        "\n",
        "\n",
        "class MlpNet(nn.Module):\n",
        "    def __init__(self, layer_sizes, input_size):\n",
        "        super(MlpNet, self).__init__()\n",
        "        layers = []\n",
        "        layer_sizes = [input_size] + layer_sizes\n",
        "        for l_id in range(len(layer_sizes) - 1):\n",
        "            if l_id == len(layer_sizes) - 2:\n",
        "                layers.append(nn.Sequential(\n",
        "                    nn.BatchNorm1d(num_features=layer_sizes[l_id], affine=False),\n",
        "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id + 1]),\n",
        "                ))\n",
        "            else:\n",
        "                layers.append(nn.Sequential(\n",
        "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id + 1]),\n",
        "                    nn.Sigmoid(),\n",
        "                    nn.BatchNorm1d(num_features=layer_sizes[l_id + 1], affine=False),\n",
        "                ))\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DeepCCA(nn.Module):\n",
        "    def __init__(self, layer_sizes1, layer_sizes2, input_size1, input_size2, outdim_size, use_all_singular_values, device=torch.device('cpu')):\n",
        "        super(DeepCCA, self).__init__()\n",
        "        self.model1 = MlpNet(layer_sizes1, input_size1).double()\n",
        "        self.model2 = MlpNet(layer_sizes2, input_size2).double()\n",
        "        #self.model1 = lambda x: x\n",
        "        #self.model2 = lambda x: x\n",
        "\n",
        "        self.loss = cca_loss(outdim_size, use_all_singular_values, device).loss\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        \"\"\"\n",
        "        x1, x2 are the vectors needs to be make correlated\n",
        "        dim=[batch_size, feats]\n",
        "        \"\"\"\n",
        "        # feature * batch_size\n",
        "        output1 = self.model1(x1)\n",
        "        output2 = self.model2(x2)\n",
        "\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "Xbpi7nJappMI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the size of the new space learned by the model (number of the new features)\n",
        "outdim_size = 10\n",
        "\n",
        "# size of the input for view 1 and view 2\n",
        "input_shape1 = 1024\n",
        "input_shape2 = 1024\n",
        "\n",
        "# number of layers with nodes in each one\n",
        "layer_sizes1 = [1024, 1024,outdim_size]\n",
        "layer_sizes2 = [1024, 1024, outdim_size]\n",
        "\n",
        "# the parameters for training the network\n",
        "learning_rate = 1e-3\n",
        "epoch_num = 10\n",
        "batch_size = 800\n",
        "\n",
        "# the regularization parameter of the network\n",
        "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
        "reg_par = 1e-5\n",
        "\n",
        "# specifies if all the singular values should get used to calculate the correlation or just the top outdim_size ones\n",
        "# if one option does not work for a network or dataset, try the other one\n",
        "use_all_singular_values = False\n",
        "\n",
        "# if a linear CCA should get applied on the learned features extracted from the networks\n",
        "# it does not affect the performance on noisy MNIST significantly\n",
        "apply_linear_cca = False\n",
        "# end of parameters section\n",
        "############"
      ],
      "metadata": {
        "id": "XIPrTc5roknf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "with open(file_loc['train'], 'rb') as f:\n",
        "    data1 = pickle.load(f)\n",
        "\n",
        "\n",
        "with open(file_loc['valid'], 'rb') as f:\n",
        "    data2 = pickle.load(f)\n",
        "\n",
        "\n",
        "with open(file_loc['test'], 'rb') as f:\n",
        "    data3 = pickle.load(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "hJub_-wQqVUE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_ghrdzKOqoQs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A2f_gamIrtKV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "#from linear_cca import linear_cca\n",
        "from torch.utils.data import BatchSampler, SequentialSampler, RandomSampler\n",
        "#from DeepCCAModels import DeepCCA\n",
        "#from utils import load_data, svm_classify\n",
        "import time\n",
        "import logging\n",
        "try:\n",
        "    import cPickle as thepickle\n",
        "except ImportError:\n",
        "    import _pickle as thepickle\n",
        "\n",
        "#import gzip\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "class Solver():\n",
        "    def __init__(self, model, linear_cca, outdim_size, epoch_num, batch_size, learning_rate, reg_par, device=torch.device('cpu')):\n",
        "        self.model = nn.DataParallel(model)\n",
        "        self.model.to(device)\n",
        "        self.epoch_num = epoch_num\n",
        "        self.batch_size = batch_size\n",
        "        self.loss = model.loss\n",
        "        self.optimizer = torch.optim.RMSprop(\n",
        "            self.model.parameters(), lr=learning_rate, weight_decay=reg_par)\n",
        "        self.device = device\n",
        "\n",
        "        self.linear_cca = linear_cca\n",
        "\n",
        "        self.outdim_size = outdim_size\n",
        "\n",
        "        formatter = logging.Formatter(\n",
        "            \"[ %(levelname)s : %(asctime)s ] - %(message)s\")\n",
        "        logging.basicConfig(\n",
        "            level=logging.DEBUG, format=\"[ %(levelname)s : %(asctime)s ] - %(message)s\")\n",
        "        self.logger = logging.getLogger(\"Pytorch\")\n",
        "        fh = logging.FileHandler(\"DCCA.log\")\n",
        "        fh.setFormatter(formatter)\n",
        "        self.logger.addHandler(fh)\n",
        "\n",
        "        self.logger.info(self.model)\n",
        "        self.logger.info(self.optimizer)\n",
        "\n",
        "    def fit(self, x1, x2, vx1=None, vx2=None, tx1=None, tx2=None, checkpoint='checkpoint.model'):\n",
        "        \"\"\"\n",
        "        x1, x2 are the vectors needs to be make correlated\n",
        "        dim=[batch_size, feats]\n",
        "        \"\"\"\n",
        "        x1.to(self.device)\n",
        "        x2.to(self.device)\n",
        "\n",
        "        data_size = x1.size(0)\n",
        "\n",
        "        if vx1 is not None and vx2 is not None:\n",
        "            best_val_loss = 0\n",
        "            vx1.to(self.device)\n",
        "            vx2.to(self.device)\n",
        "        if tx1 is not None and tx2 is not None:\n",
        "            tx1.to(self.device)\n",
        "            tx2.to(self.device)\n",
        "\n",
        "        train_losses = []\n",
        "        for epoch in range(self.epoch_num):\n",
        "            epoch_start_time = time.time()\n",
        "            print(f\"epoch number :{epoch}\")\n",
        "            self.model.train()\n",
        "            batch_idxs = list(BatchSampler(RandomSampler(\n",
        "                range(data_size)), batch_size=self.batch_size, drop_last=False))\n",
        "            for batch_idx in batch_idxs:\n",
        "                #print(f\"batch idx :{batch_idx}\")\n",
        "                self.optimizer.zero_grad()\n",
        "                batch_x1 = x1[batch_idx, :]\n",
        "                batch_x2 = x2[batch_idx, :]\n",
        "                o1, o2 = self.model(batch_x1, batch_x2)\n",
        "                loss = self.loss(o1, o2)\n",
        "                train_losses.append(loss.item())\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            train_loss = np.mean(train_losses)\n",
        "\n",
        "            info_string = \"Epoch {:d}/{:d} - time: {:.2f} - training_loss: {:.4f}\"\n",
        "            if vx1 is not None and vx2 is not None:\n",
        "                with torch.no_grad():\n",
        "                    self.model.eval()\n",
        "                    val_loss = self.test(vx1, vx2)\n",
        "                    info_string += \" - val_loss: {:.4f}\".format(val_loss)\n",
        "                    if val_loss < best_val_loss:\n",
        "                        self.logger.info(\n",
        "                            \"Epoch {:d}: val_loss improved from {:.4f} to {:.4f}, saving model to {}\".format(epoch + 1, best_val_loss, val_loss, checkpoint))\n",
        "                        best_val_loss = val_loss\n",
        "                        torch.save(self.model.state_dict(), checkpoint)\n",
        "                    else:\n",
        "                        self.logger.info(\"Epoch {:d}: val_loss did not improve from {:.4f}\".format(\n",
        "                            epoch + 1, best_val_loss))\n",
        "            else:\n",
        "                torch.save(self.model.state_dict(), checkpoint)\n",
        "            epoch_time = time.time() - epoch_start_time\n",
        "            self.logger.info(info_string.format(\n",
        "                epoch + 1, self.epoch_num, epoch_time, train_loss))\n",
        "        # train_linear_cca\n",
        "        if self.linear_cca is not None:\n",
        "            _, outputs = self._get_outputs(x1, x2)\n",
        "            self.train_linear_cca(outputs[0], outputs[1])\n",
        "\n",
        "        checkpoint_ = torch.load(checkpoint)\n",
        "        self.model.load_state_dict(checkpoint_)\n",
        "        if vx1 is not None and vx2 is not None:\n",
        "            loss = self.test(vx1, vx2)\n",
        "            self.logger.info(\"loss on validation data: {:.4f}\".format(loss))\n",
        "\n",
        "        if tx1 is not None and tx2 is not None:\n",
        "            loss = self.test(tx1, tx2)\n",
        "            self.logger.info('loss on test data: {:.4f}'.format(loss))\n",
        "\n",
        "    def test(self, x1, x2, use_linear_cca=False):\n",
        "        with torch.no_grad():\n",
        "            losses, outputs = self._get_outputs(x1, x2)\n",
        "\n",
        "            if use_linear_cca:\n",
        "                print(\"Linear CCA started!\")\n",
        "                outputs = self.linear_cca.test(outputs[0], outputs[1])\n",
        "                return np.mean(losses), outputs\n",
        "            else:\n",
        "                return np.mean(losses)\n",
        "\n",
        "    def train_linear_cca(self, x1, x2):\n",
        "        self.linear_cca.fit(x1, x2, self.outdim_size)\n",
        "\n",
        "    def _get_outputs(self, x1, x2):\n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            data_size = x1.size(0)\n",
        "            batch_idxs = list(BatchSampler(SequentialSampler(\n",
        "                range(data_size)), batch_size=self.batch_size, drop_last=False))\n",
        "            losses = []\n",
        "            outputs1 = []\n",
        "            outputs2 = []\n",
        "            for batch_idx in batch_idxs:\n",
        "                batch_x1 = x1[batch_idx, :]\n",
        "                batch_x2 = x2[batch_idx, :]\n",
        "                o1, o2 = self.model(batch_x1, batch_x2)\n",
        "                outputs1.append(o1)\n",
        "                outputs2.append(o2)\n",
        "                loss = self.loss(o1, o2)\n",
        "                losses.append(loss.item())\n",
        "        outputs = [torch.cat(outputs1, dim=0).cpu().numpy(),\n",
        "                   torch.cat(outputs2, dim=0).cpu().numpy()]\n",
        "        return losses, outputs"
      ],
      "metadata": {
        "id": "SUTa43iDqhgi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import BatchSampler, SequentialSampler\n",
        "#from DeepCCAModels import DeepCCA\n",
        "#from main import Solver\n",
        "#from utils import load_data, svm_classify\n",
        "try:\n",
        "    import cPickle as thepickle\n",
        "except ImportError:\n",
        "    import _pickle as thepickle\n",
        "\n",
        "#import gzip\n",
        "import numpy as np\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)"
      ],
      "metadata": {
        "id": "DwucKXRertyd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_eXB3FU7rx-D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S2PmzpEyvMBJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "767VJwP-rqrQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
        "# Building, training, and producing the new features by DCCA\n",
        "\n",
        "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
        "                input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
        "l_cca = None\n",
        "if apply_linear_cca:\n",
        "    l_cca = linear_cca()\n",
        "solver = Solver(model, l_cca, outdim_size, epoch_num, batch_size,\n",
        "                learning_rate, reg_par, device=device)\n",
        "train1, train2 = torch.tensor(data1[0]).double(), torch.tensor(data1[1]).double()\n",
        "#val1, val2 = torch.tensor(data2[0]).double(), torch.tensor(data2[1]).double()\n",
        "#test1, test2 = torch.tensor(data3[0]).double(), torch.tensor(data3[1]).double()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6oYfnQ3qQ0u",
        "outputId": "529f8350-bea7-4ac9-820c-304410360add"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 1 GPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:04:56,403 ] - DataParallel(\n",
            "  (module): DeepCCA(\n",
            "    (model1): MlpNet(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (1): Sigmoid()\n",
            "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (1): Sigmoid()\n",
            "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "          (1): Linear(in_features=1024, out_features=10, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (model2): MlpNet(\n",
            "      (layers): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (1): Sigmoid()\n",
            "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (1): Sigmoid()\n",
            "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "          (1): Linear(in_features=1024, out_features=10, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[ INFO : 2022-03-15 23:04:56,405 ] - RMSprop (\n",
            "Parameter Group 0\n",
            "    alpha: 0.99\n",
            "    centered: False\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    momentum: 0\n",
            "    weight_decay: 1e-05\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# val1=None\n",
        "# test1=None\n",
        "solver.fit(train1, train2)\n",
        "# TODO: Save linear_cca model if needed\n",
        "#set_size = [0, train1.size(0), train1.size(0) + val1.size(0), train1.size(0) + val1.size(0) + test1.size(0)]\n",
        "#loss, outputs = solver.test(torch.cat([train1, val1, test1], dim=0), torch.cat([train2, val2, test2], dim=0), apply_linear_cca)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbRk0LuWhKlK",
        "outputId": "fe561d0e-a658-4bb1-eff4-ceb178a84749"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
            "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
            "L, _ = torch.symeig(A, upper=upper)\n",
            "should be replaced with\n",
            "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
            "and\n",
            "L, V = torch.symeig(A, eigenvectors=True)\n",
            "should be replaced with\n",
            "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2499.)\n",
            "[ INFO : 2022-03-15 23:05:16,077 ] - Epoch 1/10 - time: 14.83 - training_loss: -8.4353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:05:30,115 ] - Epoch 2/10 - time: 14.02 - training_loss: -8.7009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:05:44,131 ] - Epoch 3/10 - time: 14.01 - training_loss: -8.8370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:05:58,212 ] - Epoch 4/10 - time: 14.08 - training_loss: -8.9196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:06:12,244 ] - Epoch 5/10 - time: 14.03 - training_loss: -8.9766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:06:26,288 ] - Epoch 6/10 - time: 14.04 - training_loss: -9.0191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:06:40,379 ] - Epoch 7/10 - time: 14.09 - training_loss: -9.0524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:06:54,519 ] - Epoch 8/10 - time: 14.14 - training_loss: -9.0795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:07:08,666 ] - Epoch 9/10 - time: 14.15 - training_loss: -9.1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number :9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[ INFO : 2022-03-15 23:07:22,764 ] - Epoch 10/10 - time: 14.09 - training_loss: -9.1220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 58s, sys: 22 s, total: 2min 20s\n",
            "Wall time: 2min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/Michaelvll/DeepCCA"
      ],
      "metadata": {
        "id": "JXehdF3_hHkZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cca-zoo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT4R0cgYgZeT",
        "outputId": "a67daafb-4090-43a6-f439-592591b8e572"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cca-zoo\n",
            "  Downloading cca_zoo-1.10.16-py3-none-any.whl (80 kB)\n",
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 30 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 80 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (3.2.2)\n",
            "Collecting scipy>=1.7\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.0.2)\n",
            "Collecting tensorly\n",
            "  Downloading tensorly-0.7.0-py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (1.1.0)\n",
            "Collecting mvlearn\n",
            "  Downloading mvlearn-0.4.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 38.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from cca-zoo) (0.11.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->cca-zoo) (3.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cca-zoo) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->cca-zoo) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->cca-zoo) (2018.9)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 50.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: scipy, nose, tensorly, mvlearn, cca-zoo\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed cca-zoo-1.10.16 mvlearn-0.4.1 nose-1.3.7 scipy-1.7.3 tensorly-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cca_zoo.models import CCA\n",
        "from cca_zoo.data import generate_covariance_data\n",
        "# %%\n",
        "(train_view_1,train_view_2),(true_weights_1,true_weights_2)=generate_covariance_data(n=281598,view_features=[1024,1024],latent_dims=1,correlation=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NT4IDZwX2Izq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_cca = CCA(latent_dims=2)\n",
        "\n",
        "linear_cca.fit([train_view_1, train_view_2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sgRqjl_2lor",
        "outputId": "4c6ea06b-cbb4-44cb-ebbb-11f4ab0a7d94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CCA(latent_dims=2, random_state=RandomState(MT19937) at 0x7F330940DAF0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = linear_cca.transform([train_view_1,train_view_2])"
      ],
      "metadata": {
        "id": "7nDoCFHE2bTQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlOaS1SM3orF",
        "outputId": "d56c3b01-ee6b-4619-b171-733f43d8c98e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVfbIDC43naW",
        "outputId": "238aaba6-c177-4b27-945a-ff6ca3fff031"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOrn0d7c3uYr",
        "outputId": "160f43d2-b308-4666-fe83-917ce154c69a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(281598, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i4Icha8H3gl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HAIthsBP2xKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}