{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb8fa5d-cb03-44e7-99f0-00011c47638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b349a53-afb6-45ae-99bc-4f8693b15e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cca-zoo in /common/home/ps1169/.local/lib/python3.7/site-packages (1.10.16)\n",
      "Requirement already satisfied: scipy>=1.7 in /common/home/ps1169/.local/lib/python3.7/site-packages (from cca-zoo) (1.7.3)\n",
      "Requirement already satisfied: joblib in /usr/lib/anaconda3/lib/python3.7/site-packages (from cca-zoo) (1.0.1)\n",
      "Requirement already satisfied: pandas in /usr/lib/anaconda3/lib/python3.7/site-packages (from cca-zoo) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /common/home/ps1169/.local/lib/python3.7/site-packages (from cca-zoo) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/anaconda3/lib/python3.7/site-packages (from cca-zoo) (3.3.4)\n",
      "Requirement already satisfied: mvlearn in /common/home/ps1169/.local/lib/python3.7/site-packages (from cca-zoo) (0.4.1)\n",
      "Requirement already satisfied: tensorly in /common/home/ps1169/.local/lib/python3.7/site-packages (from cca-zoo) (0.7.0)\n",
      "Requirement already satisfied: numpy in /usr/lib/anaconda3/lib/python3.7/site-packages (from cca-zoo) (1.20.2)\n",
      "Requirement already satisfied: seaborn in /usr/lib/anaconda3/lib/python3.7/site-packages (from cca-zoo) (0.11.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/lib/anaconda3/lib/python3.7/site-packages (from scikit-learn>=1.0->cca-zoo) (2.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/anaconda3/lib/python3.7/site-packages (from matplotlib->cca-zoo) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/anaconda3/lib/python3.7/site-packages (from matplotlib->cca-zoo) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/anaconda3/lib/python3.7/site-packages (from matplotlib->cca-zoo) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/lib/anaconda3/lib/python3.7/site-packages (from matplotlib->cca-zoo) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/anaconda3/lib/python3.7/site-packages (from matplotlib->cca-zoo) (1.3.1)\n",
      "Requirement already satisfied: six in /usr/lib/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->cca-zoo) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/anaconda3/lib/python3.7/site-packages (from pandas->cca-zoo) (2021.1)\n",
      "Requirement already satisfied: nose in /usr/lib/anaconda3/lib/python3.7/site-packages (from tensorly->cca-zoo) (1.3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cca-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2872c1-ba72-4a0d-8703-61c61dcb2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cca_zoo.models import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9995526a-b7a5-4630-9647-1a23eec0461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(type_embedding , img_embeds, rec_embeds, samples):\n",
    "    random.seed(42)\n",
    "    im_vecs = img_embeds \n",
    "    instr_vecs = rec_embeds \n",
    "\n",
    "\n",
    "    # Sort based on names to always pick same samples for medr\n",
    "#     idxs = np.argsort(names)\n",
    "#     names = names[idxs]\n",
    "\n",
    "    # Ranker\n",
    "    N = samples\n",
    "    idxs = range(N)\n",
    "    \n",
    "    glob_rank = []\n",
    "    glob_recall = {1:0.0,5:0.0,10:0.0}\n",
    "    for i in range(10):\n",
    "\n",
    "        ids = random.sample(range(0,len(img_embeds)), N)\n",
    "        im_sub = im_vecs[ids,:]\n",
    "        instr_sub = instr_vecs[ids,:]\n",
    "#         ids_sub = names[ids]\n",
    "\n",
    "        # if params.embedding == 'image':\n",
    "        if type_embedding == 'image':\n",
    "            sims = np.dot(im_sub,instr_sub.T) # for im2recipe\n",
    "        else:\n",
    "            sims = np.dot(instr_sub,im_sub.T) # for recipe2im\n",
    "\n",
    "        med_rank = []\n",
    "        recall = {1:0.0,5:0.0,10:0.0}\n",
    "\n",
    "        for ii in idxs:\n",
    "\n",
    "#             name = ids_sub[ii]\n",
    "            # get a column of similarities\n",
    "            sim = sims[ii,:]\n",
    "\n",
    "            # sort indices in descending order\n",
    "            sorting = np.argsort(sim)[::-1].tolist()\n",
    "\n",
    "            # find where the index of the pair sample ended up in the sorting\n",
    "            pos = sorting.index(ii)\n",
    "\n",
    "            if (pos+1) == 1:\n",
    "                recall[1]+=1\n",
    "            if (pos+1) <=5:\n",
    "                recall[5]+=1\n",
    "            if (pos+1)<=10:\n",
    "                recall[10]+=1\n",
    "\n",
    "            # store the position\n",
    "            med_rank.append(pos+1)\n",
    "\n",
    "        for i in recall.keys():\n",
    "            recall[i]=recall[i]/N\n",
    "\n",
    "        med = np.median(med_rank)\n",
    "        # print \"median\", med\n",
    "\n",
    "        for i in recall.keys():\n",
    "            glob_recall[i]+=recall[i]\n",
    "        glob_rank.append(med)\n",
    "\n",
    "    for i in glob_recall.keys():\n",
    "        glob_recall[i] = glob_recall[i]/10\n",
    "\n",
    "    return np.average(glob_rank), glob_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3108fea4-cdc8-4286-b260-c04fa5817fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims=[2,10,50,100,200,500,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fbfba9-3d8c-4be0-a9f9-b6086d6e78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings_train1.pkl', 'rb') as files:\n",
    "    data = pickle.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752d99f5-176a-4013-b2fd-9d0905ceef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings_val1.pkl', 'rb') as f:\n",
    "    data_validation = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05cdea06-c8c1-43e8-b311-1a38d0005bd9",
   "metadata": {},
   "source": [
    "1k Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a387e4a2-8456-439e-8f8f-ac6611b7c1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "203.1 {1: 0.0031, 5: 0.016300000000000002, 10: 0.031400000000000004}\n",
      "******************************\n",
      "Dimension: 10\n",
      "22.5 {1: 0.055400000000000005, 5: 0.19730000000000003, 10: 0.32010000000000005}\n",
      "******************************\n",
      "Dimension: 50\n",
      "2.7 {1: 0.34270000000000006, 5: 0.6896000000000001, 10: 0.8087}\n",
      "******************************\n",
      "Dimension: 100\n",
      "2.0 {1: 0.4082, 5: 0.7459, 10: 0.8452}\n",
      "******************************\n",
      "Dimension: 200\n",
      "1.7 {1: 0.48069999999999996, 5: 0.7776000000000002, 10: 0.8543000000000001}\n",
      "******************************\n",
      "Dimension: 500\n",
      "1.0 {1: 0.5474, 5: 0.7953, 10: 0.8505}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "1.0 {1: 0.5549000000000001, 5: 0.7716, 10: 0.8160000000000001}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    model=CCA(latent_dims=dims)\n",
    "    model.fit((data[0],data[1]))\n",
    "    filename='models/average_embeddings_img2text'+str(dims)+'_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    data_transform=model.transform([data_validation[0],data_validation[1]])\n",
    "    median,recall=rank('image', data_transform[0], data_transform[1], 1000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5a96706-c008-4b4d-896e-eac3ce868959",
   "metadata": {},
   "source": [
    "10k Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c4be1c-504d-446c-a848-d68d3b54fcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "2033.65 {1: 0.0004, 5: 0.0016899999999999999, 10: 0.00326}\n",
      "******************************\n",
      "Dimension: 10\n",
      "218.8 {1: 0.00682, 5: 0.030390000000000007, 10: 0.05706}\n",
      "******************************\n",
      "Dimension: 50\n",
      "17.1 {1: 0.10355, 5: 0.28631, 10: 0.40496}\n",
      "******************************\n",
      "Dimension: 100\n",
      "12.0 {1: 0.14282, 5: 0.35245, 10: 0.47501999999999994}\n",
      "******************************\n",
      "Dimension: 200\n",
      "8.0 {1: 0.19366, 5: 0.43262999999999996, 10: 0.5537299999999999}\n",
      "******************************\n",
      "Dimension: 500\n",
      "5.0 {1: 0.26037, 5: 0.51621, 10: 0.62177}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "4.9 {1: 0.28311, 5: 0.5301199999999999, 10: 0.62432}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    filename='models/average_embeddings_img2text'+str(dims)+'_model.pkl'\n",
    "    with open(filename, 'rb') as files:\n",
    "        model= pickle.load(files)\n",
    "    data_transform=model.transform([data_validation[0],data_validation[1]])\n",
    "    median,recall=rank('image', data_transform[0], data_transform[1], 10000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0142b13-23e1-467a-b0c5-b9d6b830f947",
   "metadata": {},
   "source": [
    "BEST MODEL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5b0fb69-b404-4c48-92c3-b3eebae74114",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings_test1.pkl', 'rb') as f:\n",
    "    data_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfa6a0d7-4024-48da-ae23-5d319da61809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K Samples:\n",
      "1.0 {1: 0.5495000000000001, 5: 0.7911, 10: 0.8480000000000001}\n",
      "******************************\n",
      "10K Samples:\n",
      "5.0 {1: 0.25931999999999994, 5: 0.51165, 10: 0.6194999999999999}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "filename='models/average_embeddings_img2text'+str(500)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)\n",
    "    \n",
    "data_transform=best_model.transform([data_test[0],data_test[1]])\n",
    "median,recall=rank('image', data_transform[0], data_transform[1], 1000)\n",
    "print(\"1K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)\n",
    "\n",
    "median,recall=rank('image', data_transform[0], data_transform[1], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af097c-75cf-4af2-98cf-f4f8e7138cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4375cfd0-10f2-429e-a33b-b1e676c52ab8",
   "metadata": {},
   "source": [
    "Image to title embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "183a3359-afa1-41b4-98f3-f4ae02d8cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_embeddings_train.pkl', 'rb') as files:\n",
    "    data_title = pickle.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c752f83e-f36d-4a29-9cd3-709a78958f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_embeddings_val.pkl', 'rb') as f:\n",
    "    data_validation_title = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e22e9256-a622-4e63-9134-fa47b5804775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "216.75 {1: 0.0045, 5: 0.0182, 10: 0.036}\n",
      "******************************\n",
      "Dimension: 10\n",
      "54.95 {1: 0.022399999999999996, 5: 0.0959, 10: 0.1663}\n",
      "******************************\n",
      "Dimension: 50\n",
      "9.95 {1: 0.13840000000000002, 5: 0.3827, 10: 0.5115000000000001}\n",
      "******************************\n",
      "Dimension: 100\n",
      "7.7 {1: 0.1709, 5: 0.4316999999999999, 10: 0.5548}\n",
      "******************************\n",
      "Dimension: 200\n",
      "6.8 {1: 0.20529999999999998, 5: 0.4633000000000001, 10: 0.5654999999999999}\n",
      "******************************\n",
      "Dimension: 500\n",
      "9.4 {1: 0.21880000000000002, 5: 0.43789999999999996, 10: 0.5126000000000001}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "24.95 {1: 0.19590000000000002, 5: 0.36669999999999997, 10: 0.42939999999999995}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    model=CCA(latent_dims=dims)\n",
    "    model.fit((data[0],data_title[0]))\n",
    "    filename='models/title_embeddings_img2text'+str(dims)+'_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    data_transform=model.transform([data_validation[0],data_validation_title[0]])\n",
    "    median,recall=rank('image', data_transform[0], data_transform[1], 1000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee9e47e5-f0a5-4e30-98aa-51ff160329a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "2170.8 {1: 0.00037, 5: 0.00204, 10: 0.00404}\n",
      "******************************\n",
      "Dimension: 10\n",
      "554.15 {1: 0.00243, 5: 0.011859999999999999, 10: 0.02329}\n",
      "******************************\n",
      "Dimension: 50\n",
      "89.85 {1: 0.02521, 5: 0.09215, 10: 0.15421999999999997}\n",
      "******************************\n",
      "Dimension: 100\n",
      "67.4 {1: 0.03272, 5: 0.11724000000000001, 10: 0.18913}\n",
      "******************************\n",
      "Dimension: 200\n",
      "57.85 {1: 0.04543, 5: 0.15033000000000002, 10: 0.23278000000000004}\n",
      "******************************\n",
      "Dimension: 500\n",
      "84.15 {1: 0.0613, 5: 0.18009000000000003, 10: 0.25791000000000003}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "243.5 {1: 0.06056, 5: 0.16706, 10: 0.23132999999999998}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    filename='models/title_embeddings_img2text'+str(dims)+'_model.pkl'\n",
    "    with open(filename, 'rb') as files:\n",
    "        model= pickle.load(files)\n",
    "    data_transform=model.transform([data_validation[0],data_validation_title[0]])\n",
    "    median,recall=rank('image', data_transform[0], data_transform[1], 10000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f51c663b-5de8-4d63-9d90-c5435093810a",
   "metadata": {},
   "source": [
    "BEST MODEL TO TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0de49441-4bf6-445b-a486-3ea64df8d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_embeddings_test.pkl', 'rb') as f:\n",
    "    data_test_title = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bce3cec-1d29-486c-99ef-74961b5169f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K Samples:\n",
      "6.95 {1: 0.19620000000000004, 5: 0.4614, 10: 0.5660999999999999}\n",
      "******************************\n",
      "10K Samples:\n",
      "60.9 {1: 0.04489, 5: 0.14948, 10: 0.22981}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "filename='models/title_embeddings_img2text'+str(200)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)\n",
    "    \n",
    "data_transform=best_model.transform([data_test[0],data_test_title[0]])\n",
    "median,recall=rank('image', data_transform[0], data_transform[1], 1000)\n",
    "print(\"1K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)\n",
    "\n",
    "median,recall=rank('image', data_transform[0], data_transform[1], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b5496-2fc5-4ed4-addc-d3d7ed97e99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a193ace3-df6d-4546-b4fa-9d6a2228515a",
   "metadata": {},
   "source": [
    "Image to ingredients embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "432e8bba-5b0e-410f-983a-9e7f2b7e6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ingredients_embeddings_train.pkl', 'rb') as files:\n",
    "    data_ingre = pickle.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c52f30e-fece-414c-923c-7829f89dc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ingredients_embeddings_val.pkl', 'rb') as f:\n",
    "    data_validation_ingre = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6baffa44-2654-474a-ae1b-3a18abd7c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "201.45 {1: 0.0037000000000000006, 5: 0.015600000000000003, 10: 0.031200000000000006}\n",
      "******************************\n",
      "Dimension: 10\n",
      "27.75 {1: 0.0421, 5: 0.1655, 10: 0.2762}\n",
      "******************************\n",
      "Dimension: 50\n",
      "4.7 {1: 0.23090000000000002, 5: 0.5421000000000001, 10: 0.6822}\n",
      "******************************\n",
      "Dimension: 100\n",
      "3.5 {1: 0.28470000000000006, 5: 0.5972999999999999, 10: 0.7181}\n",
      "******************************\n",
      "Dimension: 200\n",
      "2.9 {1: 0.3306, 5: 0.627, 10: 0.7270000000000001}\n",
      "******************************\n",
      "Dimension: 500\n",
      "2.8 {1: 0.361, 5: 0.6145999999999999, 10: 0.6882}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "3.6 {1: 0.3438, 5: 0.5508, 10: 0.6125999999999999}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    model=CCA(latent_dims=dims)\n",
    "    model.fit((data[0],data_ingre[0]))\n",
    "    filename='models/ingre_embeddings_img2text'+str(dims)+'_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    data_transform=model.transform([data_validation[0],data_validation_ingre[0]])\n",
    "    median,recall=rank('image', data_transform[0], data_transform[1], 1000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88894201-4369-4de6-8582-51e50b174f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "2024.7 {1: 0.00030000000000000003, 5: 0.00173, 10: 0.00338}\n",
      "******************************\n",
      "Dimension: 10\n",
      "265.6 {1: 0.00532, 5: 0.02399, 10: 0.046130000000000004}\n",
      "******************************\n",
      "Dimension: 50\n",
      "38.3 {1: 0.057109999999999994, 5: 0.17942000000000002, 10: 0.26989}\n",
      "******************************\n",
      "Dimension: 100\n",
      "27.9 {1: 0.08001, 5: 0.22845, 10: 0.32592999999999994}\n",
      "******************************\n",
      "Dimension: 200\n",
      "21.3 {1: 0.10910000000000002, 5: 0.28113, 10: 0.38176999999999994}\n",
      "******************************\n",
      "Dimension: 500\n",
      "18.6 {1: 0.14042000000000002, 5: 0.32405, 10: 0.41857000000000005}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "28.5 {1: 0.14079, 5: 0.30826, 10: 0.38906}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    filename='models/ingre_embeddings_img2text'+str(dims)+'_model.pkl'\n",
    "    with open(filename, 'rb') as files:\n",
    "        model= pickle.load(files)\n",
    "    data_transform=model.transform([data_validation[0],data_validation_ingre[0]])\n",
    "    median,recall=rank('image', data_transform[0], data_transform[1], 10000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da84ed7-8e45-4bf5-af07-a055e27b8274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa320a-7e90-4b9c-9fc1-f1d4244f0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST MODEL TO TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac3d0994-20f2-47b1-b53b-15c733ca6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ingredients_embeddings_test.pkl', 'rb') as f:\n",
    "    data_test_ingre = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17462094-4e88-4830-852c-4d90eaac6e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K Samples:\n",
      "3.0 {1: 0.35409999999999997, 5: 0.5980000000000001, 10: 0.6675}\n",
      "******************************\n",
      "10K Samples:\n",
      "19.5 {1: 0.13733, 5: 0.32005999999999996, 10: 0.41430000000000006}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "filename='models/ingre_embeddings_img2text'+str(500)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)\n",
    "    \n",
    "data_transform=best_model.transform([data_test[0],data_test_ingre[0]])\n",
    "median,recall=rank('image', data_transform[0], data_transform[1], 1000)\n",
    "print(\"1K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)\n",
    "\n",
    "median,recall=rank('image', data_transform[0], data_transform[1], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f57706-9d82-4910-af8d-f7ae4c1dc324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c26a6dbb-3da9-4e07-bcef-97115df7c569",
   "metadata": {},
   "source": [
    "Image to instructions embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d6b615d-013b-4e3f-920a-46adc5383295",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('instructions_embeddings_train.pkl', 'rb') as files:\n",
    "    data_instr = pickle.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6104554-dffa-4daf-ade8-0c1150e5df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('instructions_embeddings_val.pkl', 'rb') as f:\n",
    "    data_validation_instr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "397f200c-27b4-4946-a2ad-c101f82e71c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "189.35 {1: 0.0037000000000000006, 5: 0.0177, 10: 0.036199999999999996}\n",
      "******************************\n",
      "Dimension: 10\n",
      "33.0 {1: 0.0366, 5: 0.1485, 10: 0.24229999999999996}\n",
      "******************************\n",
      "Dimension: 50\n",
      "5.1 {1: 0.2165, 5: 0.5146, 10: 0.6540999999999999}\n",
      "******************************\n",
      "Dimension: 100\n",
      "3.7 {1: 0.26670000000000005, 5: 0.5843999999999999, 10: 0.7241}\n",
      "******************************\n",
      "Dimension: 200\n",
      "3.0 {1: 0.3119, 5: 0.6178, 10: 0.7258}\n",
      "******************************\n",
      "Dimension: 500\n",
      "3.0 {1: 0.35140000000000005, 5: 0.6132, 10: 0.6903}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "3.7 {1: 0.3357, 5: 0.5513, 10: 0.6182999999999998}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    model=CCA(latent_dims=dims)\n",
    "    model.fit((data[0],data_instr[0]))\n",
    "    filename='models/instr_embeddings_img2text'+str(dims)+'_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    data_transform=model.transform([data_validation[0],data_validation_instr[0]])\n",
    "    median,recall=rank('image', data_transform[0], data_transform[1], 1000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aa9bccb-39e1-4bd1-9d0a-3b23f2fe81b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "1868.75 {1: 0.00048000000000000007, 5: 0.00201, 10: 0.0038099999999999996}\n",
      "******************************\n",
      "Dimension: 10\n",
      "319.9 {1: 0.004999999999999999, 5: 0.022909999999999996, 10: 0.04071}\n",
      "******************************\n",
      "Dimension: 50\n",
      "43.4 {1: 0.05493, 5: 0.16638999999999998, 10: 0.24852999999999997}\n",
      "******************************\n",
      "Dimension: 100\n",
      "29.9 {1: 0.07239999999999999, 5: 0.21003, 10: 0.30542}\n",
      "******************************\n",
      "Dimension: 200\n",
      "23.0 {1: 0.09956, 5: 0.25765000000000005, 10: 0.36102}\n",
      "******************************\n",
      "Dimension: 500\n",
      "19.6 {1: 0.13107, 5: 0.30842, 10: 0.40619000000000005}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "26.1 {1: 0.13413000000000003, 5: 0.30510000000000004, 10: 0.39122}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    filename='models/instr_embeddings_img2text'+str(dims)+'_model.pkl'\n",
    "    with open(filename, 'rb') as files:\n",
    "        model= pickle.load(files)\n",
    "    data_transform=model.transform([data_validation[0],data_validation_instr[0]])\n",
    "    median,recall=rank('image', data_transform[0], data_transform[1], 10000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339edd7-da23-4aa8-9356-4c2224452402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "826da71e-a9e4-4a25-a610-7bdc34ec2fc9",
   "metadata": {},
   "source": [
    "BEST MODEL TO TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "796ea137-25ab-497b-9efc-0efb6b7d4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('instructions_embeddings_test.pkl', 'rb') as f:\n",
    "    data_test_instr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f18cf699-3e03-4de9-8c37-42688776ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K Samples:\n",
      "3.0 {1: 0.3545, 5: 0.6084999999999998, 10: 0.6870999999999999}\n",
      "******************************\n",
      "10K Samples:\n",
      "20.0 {1: 0.12906, 5: 0.30744000000000005, 10: 0.4029}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "filename='models/instr_embeddings_img2text'+str(500)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)\n",
    "    \n",
    "data_transform=best_model.transform([data_test[0],data_test_instr[0]])\n",
    "median,recall=rank('image', data_transform[0], data_transform[1], 1000)\n",
    "print(\"1K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)\n",
    "\n",
    "median,recall=rank('image', data_transform[0], data_transform[1], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d88b70-f2ad-41b8-a76c-5d34c94c3375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ca9b5-70ae-4d75-89a5-b86414fe02a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "03d29ec2-4e9e-43a0-9c0e-5af45d1ba6e0",
   "metadata": {},
   "source": [
    "Text To Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96b50c0d-d506-43e4-a1e1-7eebdffde374",
   "metadata": {},
   "source": [
    "Average Text Embedding to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9d193b5-9e47-4e37-99a6-6b73cb305825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "207.75 {1: 0.0032, 5: 0.015300000000000003, 10: 0.03180000000000001}\n",
      "******************************\n",
      "Dimension: 10\n",
      "22.9 {1: 0.0516, 5: 0.19890000000000002, 10: 0.32049999999999995}\n",
      "******************************\n",
      "Dimension: 50\n",
      "2.6 {1: 0.3504999999999999, 5: 0.6818, 10: 0.8046}\n",
      "******************************\n",
      "Dimension: 100\n",
      "2.0 {1: 0.41859999999999997, 5: 0.7384000000000001, 10: 0.8380000000000001}\n",
      "******************************\n",
      "Dimension: 200\n",
      "1.9 {1: 0.489, 5: 0.7780000000000001, 10: 0.8552}\n",
      "******************************\n",
      "Dimension: 500\n",
      "1.0 {1: 0.5522, 5: 0.7992, 10: 0.85}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "1.0 {1: 0.5630000000000001, 5: 0.7733000000000001, 10: 0.8192}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    model=CCA(latent_dims=dims)\n",
    "    model.fit((data[1],data[0]))\n",
    "    filename='models/average_embeddings_text2img'+str(dims)+'_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    data_transform=model.transform([data_validation[1],data_validation[0]])\n",
    "    median,recall=rank('text', data_transform[1], data_transform[0], 1000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e00d4f12-d1e9-47f4-b3a0-81a3253f907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "2086.9 {1: 0.00031000000000000005, 5: 0.00159, 10: 0.00315}\n",
      "******************************\n",
      "Dimension: 10\n",
      "218.55 {1: 0.00717, 5: 0.0312, 10: 0.058219999999999994}\n",
      "******************************\n",
      "Dimension: 50\n",
      "16.95 {1: 0.10942, 5: 0.29805000000000004, 10: 0.41212}\n",
      "******************************\n",
      "Dimension: 100\n",
      "11.9 {1: 0.14948, 5: 0.36008, 10: 0.47969999999999996}\n",
      "******************************\n",
      "Dimension: 200\n",
      "7.9 {1: 0.20578, 5: 0.43889999999999996, 10: 0.5559000000000001}\n",
      "******************************\n",
      "Dimension: 500\n",
      "5.0 {1: 0.27622, 5: 0.5214700000000001, 10: 0.6249}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "4.1 {1: 0.29741, 5: 0.5365, 10: 0.62957}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    filename='models/average_embeddings_text2img'+str(dims)+'_model.pkl'\n",
    "    with open(filename, 'rb') as files:\n",
    "        model= pickle.load(files)\n",
    "    data_transform=model.transform([data_validation[1],data_validation[0]])\n",
    "    median,recall=rank('text', data_transform[1], data_transform[0], 10000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b6ccc-dfe5-427b-bae5-bc7020669069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "42c55891-25b6-482f-96a5-c382f4bf576c",
   "metadata": {},
   "source": [
    "BEST MODEL TO TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78432b69-58a0-496a-9408-dbd6a0cae44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K Samples:\n",
      "1.0 {1: 0.5499, 5: 0.7941, 10: 0.849}\n",
      "******************************\n",
      "10K Samples:\n",
      "5.0 {1: 0.27286, 5: 0.5184599999999999, 10: 0.61974}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "filename='models/average_embeddings_text2img'+str(500)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)\n",
    "    \n",
    "data_transform=best_model.transform([data_test[1],data_test[0]])\n",
    "median,recall=rank('text', data_transform[1], data_transform[0], 1000)\n",
    "print(\"1K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)\n",
    "\n",
    "median,recall=rank('text', data_transform[1], data_transform[0], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970b1cf-c40d-4ae5-912e-7fd1fef04d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85839461-69ed-4f1e-a37d-686c26b9071d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f1885a6a-e780-4929-aa7f-8b897d7848e6",
   "metadata": {},
   "source": [
    "Title Embedding to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e85ae57-ceb1-46ab-9c02-b1f50beb4239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "213.15 {1: 0.004000000000000001, 5: 0.020399999999999995, 10: 0.0387}\n",
      "******************************\n",
      "Dimension: 10\n",
      "54.75 {1: 0.022, 5: 0.09439999999999998, 10: 0.16699999999999998}\n",
      "******************************\n",
      "Dimension: 50\n",
      "10.4 {1: 0.1272, 5: 0.37, 10: 0.505}\n",
      "******************************\n",
      "Dimension: 100\n",
      "8.1 {1: 0.1611, 5: 0.4244, 10: 0.5469999999999999}\n",
      "******************************\n",
      "Dimension: 200\n",
      "7.15 {1: 0.1963, 5: 0.4575, 10: 0.5572}\n",
      "******************************\n",
      "Dimension: 500\n",
      "9.8 {1: 0.21710000000000002, 5: 0.43800000000000006, 10: 0.5077}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "25.6 {1: 0.19729999999999998, 5: 0.36899999999999994, 10: 0.42639999999999995}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    model=CCA(latent_dims=dims)\n",
    "    model.fit((data_title[0],data[0]))\n",
    "    filename='models/title_embeddings_text2img'+str(dims)+'_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    data_transform=model.transform([data_validation_title[0],data_validation[0]])\n",
    "    median,recall=rank('text', data_transform[1], data_transform[0], 1000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e81c3b0-51b3-405f-87d1-6c158d837f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "2174.2 {1: 0.00041999999999999996, 5: 0.0018199999999999998, 10: 0.00381}\n",
      "******************************\n",
      "Dimension: 10\n",
      "557.65 {1: 0.0023499999999999997, 5: 0.011630000000000001, 10: 0.02212}\n",
      "******************************\n",
      "Dimension: 50\n",
      "93.2 {1: 0.023649999999999997, 5: 0.08762, 10: 0.14683000000000002}\n",
      "******************************\n",
      "Dimension: 100\n",
      "70.65 {1: 0.032659999999999995, 5: 0.11604999999999999, 10: 0.18774000000000002}\n",
      "******************************\n",
      "Dimension: 200\n",
      "61.65 {1: 0.04705000000000001, 5: 0.14939999999999998, 10: 0.23092000000000001}\n",
      "******************************\n",
      "Dimension: 500\n",
      "87.6 {1: 0.06342, 5: 0.17813999999999997, 10: 0.25476}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "245.75 {1: 0.06312999999999999, 5: 0.16746999999999998, 10: 0.23321999999999998}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    filename='models/title_embeddings_text2img'+str(dims)+'_model.pkl'\n",
    "    with open(filename, 'rb') as files:\n",
    "        model= pickle.load(files)\n",
    "    data_transform=model.transform([data_validation_title[0],data_validation[0]])\n",
    "    median,recall=rank('text', data_transform[1], data_transform[0], 10000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510b42f-9cc2-49b6-bb2c-95182282bf06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a236999b-b28a-4d06-9055-1a758d9d9dce",
   "metadata": {},
   "source": [
    "BEST MODEL TO TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c671ff90-b254-4862-954b-36a7f3e4d3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K Samples:\n",
      "7.25 {1: 0.19840000000000002, 5: 0.44600000000000006, 10: 0.5579000000000001}\n",
      "******************************\n",
      "10K Samples:\n",
      "63.85 {1: 0.04649, 5: 0.14817, 10: 0.22626}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "filename='models/title_embeddings_text2img'+str(200)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)\n",
    "    \n",
    "data_transform=best_model.transform([data_test_title[0],data_test[0]])\n",
    "median,recall=rank('text', data_transform[1], data_transform[0], 1000)\n",
    "print(\"1K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)\n",
    "\n",
    "median,recall=rank('text', data_transform[1], data_transform[0], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60088a87-5bc5-4daf-b6df-34b2bac49162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500513ce-0a42-4150-a4a3-3ed8ae8fdc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "207008ba-fec6-43ac-b472-0521f51ea0e6",
   "metadata": {},
   "source": [
    "Ingredients Embedding to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5f2fbca-a91f-4b90-8c01-07587c2abbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "204.95 {1: 0.0034000000000000002, 5: 0.0159, 10: 0.032100000000000004}\n",
      "******************************\n",
      "Dimension: 10\n",
      "27.1 {1: 0.0435, 5: 0.17009999999999997, 10: 0.2818}\n",
      "******************************\n",
      "Dimension: 50\n",
      "4.6 {1: 0.2445, 5: 0.5361, 10: 0.6706000000000001}\n",
      "******************************\n",
      "Dimension: 100\n",
      "3.6 {1: 0.29469999999999996, 5: 0.5931999999999998, 10: 0.7157000000000001}\n",
      "******************************\n",
      "Dimension: 200\n",
      "2.9 {1: 0.3403, 5: 0.6273000000000001, 10: 0.7236}\n",
      "******************************\n",
      "Dimension: 500\n",
      "2.6 {1: 0.37639999999999996, 5: 0.6214999999999999, 10: 0.6886}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "3.4 {1: 0.35330000000000006, 5: 0.5608000000000002, 10: 0.6208999999999999}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    model=CCA(latent_dims=dims)\n",
    "    model.fit((data_ingre[0],data[0]))\n",
    "    filename='models/ingre_embeddings_text2img'+str(dims)+'_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    data_transform=model.transform([data_validation_ingre[0],data_validation[0]])\n",
    "    median,recall=rank('text', data_transform[1], data_transform[0], 1000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be00f836-2eea-4dba-b9e9-bc52993cbe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "2038.8 {1: 0.0003800000000000001, 5: 0.00162, 10: 0.0032799999999999995}\n",
      "******************************\n",
      "Dimension: 10\n",
      "260.55 {1: 0.00565, 5: 0.02595, 10: 0.046669999999999996}\n",
      "******************************\n",
      "Dimension: 50\n",
      "38.4 {1: 0.0653, 5: 0.19013, 10: 0.27865}\n",
      "******************************\n",
      "Dimension: 100\n",
      "26.9 {1: 0.08896, 5: 0.24023, 10: 0.33733}\n",
      "******************************\n",
      "Dimension: 200\n",
      "20.1 {1: 0.11981, 5: 0.29298, 10: 0.3952}\n",
      "******************************\n",
      "Dimension: 500\n",
      "17.3 {1: 0.15158999999999997, 5: 0.33453, 10: 0.43034999999999995}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "25.6 {1: 0.15188, 5: 0.32114, 10: 0.40158000000000005}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    filename='models/ingre_embeddings_text2img'+str(dims)+'_model.pkl'\n",
    "    with open(filename, 'rb') as files:\n",
    "        model= pickle.load(files)\n",
    "    data_transform=model.transform([data_validation_ingre[0],data_validation[0]])\n",
    "    median,recall=rank('text', data_transform[1], data_transform[0], 10000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a164427-b263-482c-8fac-cfb308f801fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "16b2e792-e3af-4667-b912-88e810179456",
   "metadata": {},
   "source": [
    "BEST MODEL TO TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afd6f5f0-9db6-4f68-a200-4dfde7b318f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K Samples:\n",
      "2.9 {1: 0.3651, 5: 0.601, 10: 0.6733}\n",
      "******************************\n",
      "10K Samples:\n",
      "18.35 {1: 0.14953999999999998, 5: 0.3317, 10: 0.4239}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "filename='models/ingre_embeddings_text2img'+str(500)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)\n",
    "    \n",
    "data_transform=best_model.transform([data_test_ingre[0],data_test[0]])\n",
    "median,recall=rank('text', data_transform[1], data_transform[0], 1000)\n",
    "print(\"1K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)\n",
    "\n",
    "median,recall=rank('text', data_transform[1], data_transform[0], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37133952-d85d-4bab-8bd0-3b23dd4aa9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "49dd4fe2-fe85-4e95-8cf9-a9e28de21af8",
   "metadata": {},
   "source": [
    "Instructions To Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0fd9755-46c7-4bdd-bf50-5a363d88224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "189.35 {1: 0.0037000000000000006, 5: 0.0177, 10: 0.036199999999999996}\n",
      "******************************\n",
      "Dimension: 10\n",
      "33.0 {1: 0.0366, 5: 0.1485, 10: 0.24229999999999996}\n",
      "******************************\n",
      "Dimension: 50\n",
      "5.1 {1: 0.2165, 5: 0.5146, 10: 0.6540999999999999}\n",
      "******************************\n",
      "Dimension: 100\n",
      "3.7 {1: 0.26670000000000005, 5: 0.5843999999999999, 10: 0.7241}\n",
      "******************************\n",
      "Dimension: 200\n",
      "3.0 {1: 0.3119, 5: 0.6178, 10: 0.7258}\n",
      "******************************\n",
      "Dimension: 500\n",
      "3.0 {1: 0.35140000000000005, 5: 0.6132, 10: 0.6903}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "3.7 {1: 0.3357, 5: 0.5513, 10: 0.6182999999999998}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    model=CCA(latent_dims=dims)\n",
    "    model.fit((data_instr[0],data[0]))\n",
    "    filename='models/instr_embeddings_text2img'+str(dims)+'_model.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    data_transform=model.transform([data_validation_instr[0],data_validation[0]])\n",
    "    median,recall=rank('image', data_transform[1], data_transform[0], 1000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f85e721c-bfb9-4910-8736-f6bd367ee4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 2\n",
      "1868.75 {1: 0.00048000000000000007, 5: 0.00201, 10: 0.0038099999999999996}\n",
      "******************************\n",
      "Dimension: 10\n",
      "319.9 {1: 0.004999999999999999, 5: 0.022909999999999996, 10: 0.04071}\n",
      "******************************\n",
      "Dimension: 50\n",
      "43.4 {1: 0.05493, 5: 0.16638999999999998, 10: 0.24852999999999997}\n",
      "******************************\n",
      "Dimension: 100\n",
      "29.9 {1: 0.07239999999999999, 5: 0.21003, 10: 0.30542}\n",
      "******************************\n",
      "Dimension: 200\n",
      "23.0 {1: 0.09956, 5: 0.25765000000000005, 10: 0.36102}\n",
      "******************************\n",
      "Dimension: 500\n",
      "19.6 {1: 0.13107, 5: 0.30842, 10: 0.40619000000000005}\n",
      "******************************\n",
      "Dimension: 1000\n",
      "26.1 {1: 0.13413000000000003, 5: 0.30510000000000004, 10: 0.39122}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for dims in latent_dims:\n",
    "    filename='models/instr_embeddings_text2img'+str(dims)+'_model.pkl'\n",
    "    with open(filename, 'rb') as files:\n",
    "        model= pickle.load(files)\n",
    "    data_transform=model.transform([data_validation_instr[0],data_validation[0]])\n",
    "    median,recall=rank('image', data_transform[1], data_transform[0], 10000)\n",
    "    print(\"Dimension: \"+str(dims))\n",
    "    print(median,recall)\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630fe6b5-544e-4570-817c-303d086cf44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8c827ebf-ad1e-4bb7-97bc-6362adffbaca",
   "metadata": {},
   "source": [
    "BEST MODEL TO TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8618eb0c-f9a4-42ec-b060-88934da40917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1K Samples:\n",
      "2.9 {1: 0.3619, 5: 0.6194, 10: 0.6922}\n",
      "******************************\n",
      "10K Samples:\n",
      "18.9 {1: 0.13655, 5: 0.31639999999999996, 10: 0.41279000000000005}\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "filename='models/instr_embeddings_text2img'+str(500)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)\n",
    "    \n",
    "data_transform=best_model.transform([data_test_instr[0],data_test[0]])\n",
    "median,recall=rank('text', data_transform[1], data_transform[0], 1000)\n",
    "print(\"1K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)\n",
    "\n",
    "median,recall=rank('text', data_transform[1], data_transform[0], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c14e9d-3cfb-4292-a401-0a2009ccc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "median,recall=rank('text', data_transform[1], data_transform[0], 10000)\n",
    "print(\"10K Samples:\")\n",
    "print(median,recall)\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4f224fa-ca77-4e3c-b97a-232f7afa4ad6",
   "metadata": {},
   "source": [
    "PLOT IMAGE TO RECIPE "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b0bdf37-c39c-48d5-9b41-4faee65500f0",
   "metadata": {},
   "source": [
    "1K SAMPLES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc512066-7c59-48b0-94da-73395dc11734",
   "metadata": {},
   "source": [
    "Image to Average Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3df74fc-730d-432b-8476-72791830748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac45c7e0-d49f-422f-b611-faf40613ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_average=[]\n",
    "recall_1_average=[]\n",
    "recall_5_average=[]\n",
    "recall_10_average=[]\n",
    "for dims in latent_dims:\n",
    "    file_store='outputs/recipe2img_10K_samples/average_embeddings_text2img'+str(dims)+'_model_output.pkl'\n",
    "    with open(file_store, 'rb') as files:\n",
    "        data_output= pickle.load(files)\n",
    "    median_average.append(data_output[0])\n",
    "    recall_1_average.append(data_output[1][1])\n",
    "    recall_5_average.append(data_output[1][5])\n",
    "    recall_10_average.append(data_output[1][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45181f2a-73a8-4c29-9324-eb6730cc266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_title=[]\n",
    "recall_1_title=[]\n",
    "recall_5_title=[]\n",
    "recall_10_title=[]\n",
    "for dims in latent_dims:\n",
    "    file_store='outputs/recipe2img_10K_samples/title_embeddings_text2img'+str(dims)+'_model_output.pkl'\n",
    "    with open(file_store, 'rb') as files:\n",
    "        data_output= pickle.load(files)\n",
    "    median_title.append(data_output[0])\n",
    "    recall_1_title.append(data_output[1][1])\n",
    "    recall_5_title.append(data_output[1][5])\n",
    "    recall_10_title.append(data_output[1][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee152cdf-2f05-4d9b-9d2b-58e94a2192f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ingre=[]\n",
    "recall_1_ingre=[]\n",
    "recall_5_ingre=[]\n",
    "recall_10_ingre=[]\n",
    "for dims in latent_dims:\n",
    "    file_store='outputs/recipe2img_10K_samples/ingre_embeddings_text2img'+str(dims)+'_model_output.pkl'\n",
    "    with open(file_store, 'rb') as files:\n",
    "        data_output= pickle.load(files)\n",
    "    median_ingre.append(data_output[0])\n",
    "    recall_1_ingre.append(data_output[1][1])\n",
    "    recall_5_ingre.append(data_output[1][5])\n",
    "    recall_10_ingre.append(data_output[1][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c28deb03-4a03-415a-ad62-e8784c4bd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_instr=[]\n",
    "recall_1_instr=[]\n",
    "recall_5_instr=[]\n",
    "recall_10_instr=[]\n",
    "for dims in latent_dims:\n",
    "    file_store='outputs/recipe2img_10K_samples/instr_embeddings_text2img'+str(dims)+'_model_output.pkl'\n",
    "    with open(file_store, 'rb') as files:\n",
    "        data_output= pickle.load(files)\n",
    "    median_instr.append(data_output[0])\n",
    "    recall_1_instr.append(data_output[1][1])\n",
    "    recall_5_instr.append(data_output[1][5])\n",
    "    recall_10_instr.append(data_output[1][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e3e1e6e-4863-445b-b704-942585a5e1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(latent_dims,median_average,label='Average')\n",
    "plt.plot(latent_dims,median_title,label='Title')\n",
    "plt.plot(latent_dims,median_ingre,label='Ingredients')\n",
    "plt.plot(latent_dims,median_instr,label='Instructions')\n",
    "plt.legend()\n",
    "plt.title(\"Recipe to Image Median Rank 10K samples\")\n",
    "plt.savefig('image_output/recipe2img_10k_samples.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e25b4be1-78ab-413b-96e9-9c798cdba76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=data[2]\n",
    "chicken_lasagna_idx=np.where(ids == 'f79f91650c')[0][0]\n",
    "lasagna_idx=np.where(ids == '003971cf31')[0][0]\n",
    "salad_idx=np.where(ids == '001f8b08ac')[0][0]\n",
    "chicken_salad_idx=np.where(ids == '09f70a1c31')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b76e0c4f-eb3a-4331-83d6-69f8a1323b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='models/average_embeddings_img2text'+str(500)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81f61d9f-0a76-4646-8a41-4346f7515d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281598, 500)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transform=best_model.transform([data[0],data[1]])\n",
    "data_transform[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00c9b648-5036-48a0-b372-87a3a88d81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken_lasagna_imgvec=data_transform[0][chicken_lasagna_idx]\n",
    "lasagna_imgvec=data_transform[0][lasagna_idx]\n",
    "salad_imgvec=data_transform[0][salad_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68176cfa-c9a1-43e2-af32-b6874d7f8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken_lasagna_textvec=data_transform[1][chicken_lasagna_idx]\n",
    "lasagna_textvec=data_transform[1][lasagna_idx]\n",
    "salad_textvec=data_transform[1][salad_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "494f8c37-f25d-4d4f-badf-449e4d05c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken_vec=np.subtract(chicken_lasagna_imgvec,lasagna_imgvec)\n",
    "chicken_salad_vec=np.add(chicken_vec,salad_imgvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "448e6f70-db98-4c53-a4e6-6717148b16fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c4cbd0d736'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = np.dot(chicken_salad_vec,data_transform[1].T)\n",
    "sorting = np.argsort(sims)[::-1].tolist()\n",
    "ans_index=sorting[0]\n",
    "ans_id=data[2][ans_index]\n",
    "ans_id"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d36ffd24-91a0-4bbe-bb22-9d743dc6c2bb",
   "metadata": {},
   "source": [
    "ABOVE ID IS FOR MANGO CURRY SALAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e3b4e-30ca-4e10-b416-046296ad0f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a8ce0-4ee4-414e-9890-dcdce788bcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "d135bf7c-8660-4bea-8d3e-dfa58db97b5f",
   "metadata": {},
   "source": [
    "TITLE TO IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f236734-81a2-416c-99f7-b039884e9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='models/title_embeddings_img2text'+str(200)+'_model.pkl'\n",
    "with open(filename, 'rb') as files:\n",
    "    best_model= pickle.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc707f1-3c54-4207-ace6-301d6aff6f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281598, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transform=best_model.transform([data[1],data[0]])\n",
    "data_transform[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09c9333a-e77a-4fbd-b103-3523c6c4f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken_lasagna=data_transform[0][chicken_lasagna_idx]\n",
    "lasagna=data_transform[0][lasagna_idx]\n",
    "salad=data_transform[0][salad_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef7bf01-9571-4c6e-abe2-d073ecd8f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken_vec=np.subtract(chicken_lasagna,lasagna)\n",
    "chicken_salad_vec=np.add(chicken_vec,salad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15697a22-f3e5-4b64-9b57-1ca79d2074c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c4cbd0d736'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = np.dot(chicken_salad_vec,data_transform[1].T) # for recipe2im\n",
    "sorting = np.argsort(sims)[::-1].tolist()\n",
    "ans_index=sorting[0]\n",
    "ans_id=data[2][ans_index]\n",
    "ans_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60b51c-8c24-4087-8093-013690e65ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
